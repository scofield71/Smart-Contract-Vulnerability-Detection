In this project I have used ScrawlD Dataset (https://github.com/sujeetc/ScrawlD)
which marks up the real world solidity files running on Ethereum as per the vulnerabilities
present in them.

I have extracted all those solidity files from Ethereum through an API endpoint from Ethereum
using APICallingScript.js in AllScript folder.

Then each solidity files have to be compiled on the respective compiler versions. So, i have 
first grouped those solidity files and then compiled them collectively by installing various
compiler versions from NPM and then compiled them using AllScripts/compilationScriptBasedOnCompilerVersion.js.
I have extracted the opcodes sequences from each file and stored it in text files.

Some files can't be compiled and results in empty text file creation so the respective files were
found out and deleted using All Scripts/ emptyFileCount.js

Similar opcodes were grouped and the hexaddresses were removed from the opcode sequences.
Seperate filtered files were created after this operation. This is performed under
filteringAndReducingOpcodes.js file.

Now we have filtered opcode sequences without hexaddress sequences and after clubbing similar 
opcodes together in one and then their bigrams are created from each file. Each bigram 
represents a feature and we have calculated probabilities of finding bigram in each file
and stored the results in a CSV file. This operation is done under /multiLabelledBigramNew.js.

For more information you can refer: https://ieeexplore.ieee.org/document/8967006

